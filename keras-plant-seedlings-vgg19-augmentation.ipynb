{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "735a0673b257fa7f8d8bbe5f86639f80a37868ee"
   },
   "source": [
    "## Keras VGG19 + Data Augmentation + Transfer Learning, Kaggle Plant Seedlings Classification \n",
    "\n",
    "Simple Keras implementation with Transfer Learning. \n",
    "\n",
    "* You must run this on a GPU.\n",
    "<br>\n",
    "\n",
    "[MY GITHUB](https://github.com/AtriSaxena/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3326f1388ce01fa6d1989afc682202b726247609",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n",
    "              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
    "NUM_CATEGORIES = len(CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8660ec6c99788ab52f55ca8dd2a5a8724c085fc0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 1987\n",
    "data_dir = '../input/'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "sample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7099ad30d67386be7980bc2e414bb6a60ff4f0ef"
   },
   "source": [
    "### Number of training images for each Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "812183d40b80919fb5d2b0a09a2cb8cba15bc1d6",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for category in CATEGORIES:\n",
    "    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6763d312e10f497b0a6c434508cca9a1dfd3621",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "for category_id, category in enumerate(CATEGORIES):\n",
    "    for file in os.listdir(os.path.join(train_dir, category)):\n",
    "        train.append(['train/{}/{}'.format(category, file), category_id, category])\n",
    "train = pd.DataFrame(train, columns=['file', 'category_id', 'category'])\n",
    "train.head(2)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e51cc8c2972498dc59770ad38789648d911e3ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "for file in os.listdir(test_dir):\n",
    "    test.append(['test/{}'.format(file), file])\n",
    "test = pd.DataFrame(test, columns=['filepath', 'file'])\n",
    "test.head(2)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f4631dde3a93b40fe3e58fdcbdc38f9e5a6bd70"
   },
   "source": [
    "### See some of the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dff15c1e9c995eac5ff5ec7fb4e2d9e82c551b8b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(NUM_CATEGORIES, NUM_CATEGORIES))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(NUM_CATEGORIES, NUM_CATEGORIES), axes_pad=0.05)\n",
    "i = 0\n",
    "for category_id, category in enumerate(CATEGORIES):\n",
    "    for filepath in train[train['category'] == category]['file'].values[:NUM_CATEGORIES]:\n",
    "        ax = grid[i]\n",
    "        img = Image.open(\"../input/\"+filepath)\n",
    "        img = img.resize((240,240))\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        if i % NUM_CATEGORIES == NUM_CATEGORIES - 1:\n",
    "            ax.text(250, 112, filepath.split('/')[1], verticalalignment='center')\n",
    "        i += 1\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "152a64f1027292a5fe224f7640322b2eee730015"
   },
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86eb75b30a81fb16a022fb79f0f4bdfff3ba7e09",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (240, 240, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae2c3181315d6c87ae7988e32fcb8fafd4e264f4"
   },
   "source": [
    "### Freezing first few layers\n",
    "\n",
    "freeze the first few layers as these layers will be detecting edges and blobs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b12bc24293fc95f57cb5b905592ea581410e86ce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb32f72977f25a4b96b1b247089e1068064b1bf7"
   },
   "source": [
    "### Adding output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "877d5e590c492e0aa39a6d701d513314ae0f33cf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(12, activation=\"softmax\")(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3595451acbc2ada1a9498f5d2a0822707d654eb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final = Model(input = model.input, output = predictions)\n",
    "#compling our model\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c69f442273fa79483146c1152396614c18b35dee",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_final.summary() #Model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d9be455e5ae87f7ca50d4914e8f83f2aba72de4"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe1f5492d35f66ea15bb4afbdb47201f8dc6be13",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(\n",
    "            rotation_range=360.,\n",
    "            width_shift_range=0.3,\n",
    "            height_shift_range=0.3,\n",
    "            zoom_range=0.3,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "00940fef5caf50923526641e52d10a8a2dd21bb4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = \"../input/train\"\n",
    "train_generator = gen.flow_from_directory(\n",
    "                        train_data_dir,\n",
    "                        target_size = (240, 240),\n",
    "                        batch_size = 16, \n",
    "                        class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7c88ef71b87222e42507af04a109677613a08529",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8292b1ad43391d637d46fd10eaeb040715b32d3d"
   },
   "source": [
    "### Train our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23257aaa09dbbc2d21c2bac200a9aa6a40daec7a",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_final.fit_generator(\n",
    "                    train_generator,\n",
    "                    epochs = 50,\n",
    "                    shuffle= True,\n",
    "                    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c9f509ca511efffffa08620a98c1c3f86bb966e"
   },
   "source": [
    "## Predicting the test images from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e5c1aab36b8f5385e23ed109fd5297bcdf5a06f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = train_generator.class_indices  \n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "334057468e9fc151e9b06758efe40189a37d7797",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Invert Mapping\n",
    "classes = {v: k for k, v in classes.items()}\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d6fda46ac6fe15d5744f4373ae328b2cafbcfc8"
   },
   "source": [
    "### Prediction on each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42ec1709f17c7702add9357fbae6e9a396349829",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for filepath in test['filepath']:\n",
    "    img = cv2.imread(os.path.join(data_dir,filepath))\n",
    "    img = cv2.resize(img,(240,240))\n",
    "    img = np.asarray(img)\n",
    "    img = img.reshape(1,240,240,3)\n",
    "    pred = model_final.predict(img)\n",
    "    prediction.append(classes.get(pred.argmax(axis=-1)[0])) #Invert Mapping helps to map Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "552f422733c54922988dd88776ba640589c4a06a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.drop(columns =['filepath']) #Remove file path from test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b562c5a66684e4914ca759e0f021f22890090517",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1cfa63d5328b6b10171738a77391bc0446be8048",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame({'species': prediction})\n",
    "test =test.join(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "87a5d1e61b28c36e1f5ff659799bc8d6d2c0de48"
   },
   "source": [
    "### Final submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ac1053202f8ffa448d967df57477193942a8dcb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1f47feb769dd7a905215ca818efb6d1b4e3dc97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
